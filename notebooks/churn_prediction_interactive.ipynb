{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction Model Training - Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Foundational Exploration & Quick Wins (JupyterHub)\n",
    "\n",
    "This notebook adapts the functionality from the `xgboost_script.py` for interactive development and exploration within a JupyterHub environment running on Kubernetes.\n",
    "\n",
    "**Goals:**\n",
    "*   Rapid iteration and data exploration.\n",
    "*   Initial model development.\n",
    "*   Demonstrate an interactive ML environment within the k8s cluster.\n",
    "\n",
    "**Assumptions:**\n",
    "*   The preprocessed `train.csv` and `test.csv` files are accessible (e.g., via a mounted PVC).\n",
    "*   Hyperparameters are manually defined in this notebook for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split # Though script uses pre-split data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging (optional for notebooks, but good practice)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Parameters and File Paths\n",
    "\n",
    "Update these paths based on where your data is accessible in the JupyterHub environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters (manual definition for notebook) ---\n",
    "params = {\n",
    "    'max_depth': 5,        # Corresponds to SM_HP_MAX_DEPTH\n",
    "    'eta': 0.2,            # Corresponds to SM_HP_ETA (learning rate)\n",
    "    'min_child_weight': 1, # Corresponds to SM_HP_MIN_CHILD_WEIGHT\n",
    "    'subsample': 0.8,      # Corresponds to SM_HP_SUBSAMPLE\n",
    "    'objective': 'binary:logistic',\n",
    "    'num_round': 100       # Number of boosting rounds (n_estimators for scikit-learn wrapper)\n",
    "    # 'eval_metric': ['auc', 'logloss'] # XGBoost native API can take this\n",
    "}\n",
    "\n",
    "# --- File Paths (Update these!) ---\n",
    "# Example: If your PVC is mounted at /home/jovyan/work\n",
    "BASE_PATH = '/opt/ml/processing' # Or your equivalent path in JupyterHub\n",
    "INPUT_DATA_PATH = os.path.join(BASE_PATH, 'input', 'data') # Path to preprocessed data dir\n",
    "TRAIN_DATA_FILE = os.path.join(INPUT_DATA_PATH, 'train', 'train.csv')\n",
    "VALID_DATA_FILE = os.path.join(INPUT_DATA_PATH, 'test', 'test.csv') # Using test set as validation\n",
    "\n",
    "MODEL_OUTPUT_DIR = os.path.join(BASE_PATH, 'model_notebook') # Where to save the model from notebook\n",
    "METRICS_OUTPUT_DIR = os.path.join(BASE_PATH, 'output_notebook') # Where to save metrics from notebook\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_FILE_PATH = os.path.join(MODEL_OUTPUT_DIR, 'xgboost-model-notebook.xgb')\n",
    "METRICS_FILE_PATH = os.path.join(METRICS_OUTPUT_DIR, 'metrics-notebook.json')\n",
    "\n",
    "logger.info(f\"Train data path: {TRAIN_DATA_FILE}\")\n",
    "logger.info(f\"Validation data path: {VALID_DATA_FILE}\")\n",
    "logger.info(f\"Model output path: {MODEL_FILE_PATH}\")\n",
    "logger.info(f\"Metrics output path: {METRICS_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Loading training data...\")\n",
    "    train_df = pd.read_csv(TRAIN_DATA_FILE)\n",
    "    logger.info(f\"Training data loaded. Shape: {train_df.shape}\")\n",
    "\n",
    "    logger.info(\"Loading validation data...\")\n",
    "    valid_df = pd.read_csv(VALID_DATA_FILE)\n",
    "    logger.info(f\"Validation data loaded. Shape: {valid_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error loading data: {e}. Please check your file paths.\")\n",
    "    raise\n",
    "\n",
    "# Assuming the first column is the target 'Churn' and was named appropriately during preprocessing\n",
    "# If your CSVs have a different target column name, adjust here.\n",
    "TARGET_COLUMN = train_df.columns[0] # Or explicitly 'Churn' if that's the name\n",
    "logger.info(f\"Identified target column: {TARGET_COLUMN}\")\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "y_train = train_df[TARGET_COLUMN]\n",
    "\n",
    "X_valid = valid_df.drop(columns=[TARGET_COLUMN])\n",
    "y_valid = valid_df[TARGET_COLUMN]\n",
    "\n",
    "logger.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "logger.info(f\"X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}\")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialize and Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing XGBoost model...\")\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=params['objective'],\n",
    "    max_depth=params['max_depth'],\n",
    "    learning_rate=params['eta'], # 'eta' is learning_rate in XGBClassifier\n",
    "    min_child_weight=params['min_child_weight'],\n",
    "    subsample=params['subsample'],\n",
    "    n_estimators=params['num_round'], # 'num_round' is n_estimators\n",
    "    # eval_metric=params.get('eval_metric', 'logloss'), # Can specify eval_metric for early stopping\n",
    "    use_label_encoder=False # Suppress a warning for newer XGBoost versions\n",
    ")\n",
    "logger.info(\"XGBoost model initialized.\")\n",
    "\n",
    "logger.info(\"Starting model training...\")\n",
    "# For XGBClassifier, eval_set expects a list of tuples (X, y)\n",
    "model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False) # verbose=True for iteration details\n",
    "logger.info(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Saving the trained model to {MODEL_FILE_PATH}\")\n",
    "model.save_model(MODEL_FILE_PATH)\n",
    "logger.info(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Evaluating the model on validation data.\")\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "auc = roc_auc_score(y_valid, y_pred_proba)\n",
    "\n",
    "logger.info(f\"Model evaluation completed. Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "# Print metrics (similar to SageMaker HPO format for consistency if desired)\n",
    "print(f\"validation:accuracy: {accuracy}\")\n",
    "print(f\"validation:auc: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save Metrics to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Saving evaluation metrics to {METRICS_FILE_PATH}\")\n",
    "metrics_data = {'accuracy': accuracy, 'auc': auc}\n",
    "\n",
    "with open(METRICS_FILE_PATH, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=4)\n",
    "logger.info(\"Metrics saved successfully.\")\n",
    "print(f\"Metrics saved to {METRICS_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. (Optional) Load Model and Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading model from {MODEL_FILE_PATH} for a test prediction.\")\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model(MODEL_FILE_PATH)\n",
    "logger.info(\"Model loaded successfully.\")\n",
    "\n",
    "# Make a prediction on the first few validation samples\n",
    "sample_predictions = loaded_model.predict(X_valid.head())\n",
    "sample_probas = loaded_model.predict_proba(X_valid.head())[:,1]\n",
    "\n",
    "logger.info(f\"Sample predictions on X_valid.head(): {sample_predictions}\")\n",
    "logger.info(f\"Sample probabilities on X_valid.head(): {sample_probas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1.  Ensure your data paths (`TRAIN_DATA_FILE`, `VALID_DATA_FILE`) are correct for your JupyterHub environment.\n",
    "2.  Experiment with different hyperparameters.\n",
    "3.  Explore the data further (visualizations, feature importance from the model).\n",
    "4.  This notebook can serve as a prototype for the automated pipeline steps in Phase 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
