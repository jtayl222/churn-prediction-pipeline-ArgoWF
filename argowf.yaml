apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: churn-pipeline
  namespace: argowf
spec:
  entrypoint: churn-pipeline
  serviceAccountName: argo-workflow # Ensure this service account has rights to read secrets if necessary, usually default does
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: churn-data-pvc
    - name: script
      configMap:
        name: churn-pipeline-scripts
  templates:
    - name: churn-pipeline
      dag:
        tasks:
          - name: preprocess
            template: preprocess
          - name: train
            dependencies: [preprocess]
            template: train
          - name: evaluate
            dependencies: [train]
            template: evaluate
    - name: preprocess
      container:
        image: jtayl22/preprocess:0.23-3 # <<< UPDATED IMAGE NAME
        command: ["sh", "-c"]
        args:
          - |
            pip install mlflow boto3 pandas scikit-learn # Ensure all deps are here
            python3 /scripts/preprocessing.py \
              --input-data-path /opt/ml/processing/input/WA_Fn-UseC_-Telco-Customer-Churn.csv \
              --output-train-path /opt/ml/processing/output/train/train.csv \
              --output-test-path /opt/ml/processing/output/test/test.csv \
              --test-split-ratio 0.2 \
              --random-state 42 \
              --mlflow-experiment-name "Churn_Prediction_Experiment"
        env:
          - name: MLFLOW_TRACKING_URI
            value: "http://mlflow.mlflow.svc.cluster.local:5000" # Your MLflow server
        envFrom:
          - secretRef:
              name: minio-credentials-wf
        volumeMounts:
          - name: data
            mountPath: "/opt/ml/processing"
          - name: script
            mountPath: "/scripts"
        resources:
          limits:
            cpu: "1"
            memory: "2Gi"
          requests:
            cpu: "0.5"
            memory: "1Gi"
    - name: train
      container:
        image: jtayl22/xgboost:1.5-2
        command: ["sh", "-c"]
        args:
          - |
            pip install scikit-learn mlflow boto3 xgboost pandas # Ensure all deps are here
            python3 /scripts/xgboost_script.py \
              --train-data-path /opt/ml/processing/output/train/train.csv \
              --valid-data-path /opt/ml/processing/output/test/test.csv \
              --model-output-path /opt/ml/processing/model/xgboost-model \
              --metrics-output-path /opt/ml/processing/output/metrics.json \
              --mlflow-experiment-name "Churn_Prediction_XGBoost"
        env:
          - name: MLFLOW_TRACKING_URI
            value: "http://mlflow.mlflow.svc.cluster.local:5000" # Your MLflow server
        envFrom:
          - secretRef:
              name: minio-credentials-wf
        volumeMounts:
          - name: data
            mountPath: "/opt/ml/processing"
          - name: script
            mountPath: "/scripts"
        resources:
          limits:
            cpu: "4"
            memory: "16Gi"
          requests:
            cpu: "2"
            memory: "8Gi"
    - name: evaluate # Keep this commented if evaluation.py is not ready or not in ConfigMap
      container:
        image: jtayl22/xgboost:1.5-2
        command: ["sh", "-c"]
        args:
          - |
            pip install scikit-learn mlflow boto3 xgboost pandas
            python3 /scripts/evaluation_script.py \
              --valid-data-path /opt/ml/processing/output/test/test.csv \
              --model-path /opt/ml/processing/model/xgboost-model \
              --metrics-output-path /opt/ml/processing/output/eval_metrics.json \
              --mlflow-experiment-name "Churn_Prediction_XGBoost"
        env:
          - name: MLFLOW_TRACKING_URI
            value: "http://mlflow.mlflow.svc.cluster.local:5000"
        envFrom:
          - secretRef:
              name: minio-credentials-wf
        volumeMounts:
          - name: data
            mountPath: "/opt/ml/processing"
          - name: script
            mountPath: "/scripts"
        resources:
          limits:
            cpu: "2"
            memory: "4Gi"
          requests:
            cpu: "1"
            memory: "2Gi"
